# Buildsheet autogenerated by ravenadm tool -- Do not edit.

NAMEBASE=		python-snowballstemmer
VERSION=		2.2.0
KEYWORDS=		python
VARIANTS=		v12 v13
SDESC[v12]=		Snowball stemming library collection (3.12)
SDESC[v13]=		Snowball stemming library collection (3.13)
HOMEPAGE=		https://github.com/snowballstem/snowball
CONTACT=		Python_Automaton[python@ironwolf.systems]

DOWNLOAD_GROUPS=	main
SITES[main]=		PYPIWHL/ed/dc/c02e01294f7265e63a7315fe086dd1df7dacb9f840a804da846b96d01b96
DISTFILE[1]=		snowballstemmer-2.2.0-py2.py3-none-any.whl:main
DIST_SUBDIR=		python-src
DF_INDEX=		1
SPKGS[v12]=		single
SPKGS[v13]=		single

OPTIONS_AVAILABLE=	PY312 PY313
OPTIONS_STANDARD=	none
VOPTS[v12]=		PY312=ON PY313=OFF
VOPTS[v13]=		PY312=OFF PY313=ON

DISTNAME=		snowballstemmer-2.2.0.dist-info

GENERATED=		yes

[PY312].USES_ON=			python:v12,wheel

[PY313].USES_ON=			python:v13,wheel

[FILE:3431:descriptions/desc.single]
Snowball stemming library collection for Python
===============================================

Python 3 (>= 3.3) is supported.  We no longer actively support Python 2 as
the Python developers stopped supporting it at the start of 2020.  Snowball
2.1.0 was the last release to officially support Python 2.

What is Stemming?
-----------------

Stemming maps different forms of the same word to a common "stem" - for
example, the English stemmer maps *connection*, *connections*,
*connective*,
*connected*, and *connecting* to *connect*.  So a searching for *connected*
would also find documents which only have the other forms.

This stem form is often a word itself, but this is not always the case as
this
is not a requirement for text search systems, which are the intended field
of
use.  We also aim to conflate words with the same meaning, rather than all
words with a common linguistic root (so *awe* and *awful* don't have the
same
stem), and over-stemming is more problematic than under-stemming so we tend
not
to stem in cases that are hard to resolve.  If you want to always reduce
words
to a root form and/or get a root form which is itself a word then
Snowball's
stemming algorithms likely aren't the right answer.

How to use library
------------------

The snowballstemmer module has two functions.

The ``snowballstemmer.algorithms`` function returns a list of available
algorithm names.

The ``snowballstemmer.stemmer function takes an algorithm name and returns
a
Stemmer`` object.

Stemmer objects have a ``Stemmer.stemWord(word) method and a
Stemmer.stemWords(word[])`` method.

.. code-block:: python

   import snowballstemmer

   stemmer = snowballstemmer.stemmer('english');
   print(stemmer.stemWords("We are the world".split()));

Automatic Acceleration
----------------------

[PyStemmer] is a wrapper module for
Snowball's libstemmer_c and should provide results 100% compatible to
**snowballstemmer**.

**PyStemmer** is faster because it wraps generated C versions of the
stemmers;
**snowballstemmer** uses generate Python code and is slower but offers a
pure
Python solution.

If PyStemmer is installed, ``snowballstemmer.stemmer returns a PyStemmer
Stemmer object which provides the same Stemmer.stemWord() and
Stemmer.stemWords()`` methods.

Benchmark
~~~~~~~~~

This is a crude benchmark which measures the time for running each stemmer
on
every word in its sample vocabulary (10,787,583 words over 26 languages). 
It's
not a realistic test of normal use as a real application would do much more
than just stemming.  It's also skewed towards the stemmers which do more
work
per word and towards those with larger sample vocabularies.

* Python 2.7 + **snowballstemmer** : 13m00s (15.0 * PyStemmer)
* Python 3.7 + **snowballstemmer** : 12m19s (14.2 * PyStemmer)
* PyPy 7.1.1 (Python 2.7.13) + **snowballstemmer** : 2m14s (2.6 *
PyStemmer)
* PyPy 7.1.1 (Python 3.6.1) + **snowballstemmer** : 1m46s (2.0 * PyStemmer)
* Python 2.7 + **PyStemmer** : 52s

For reference the equivalent test for C runs in 9 seconds.

These results are for Snowball 2.0.0.  They're likely to evolve over time
as
the code Snowball generates for both Python and C continues to improve (for
a much older test over a different set of stemmers using Python 2.7,
**snowballstemmer** was 30 times slower than **PyStemmer**, or 9 times
slower
with **PyPy**).

The message to take away is that if you're stemming a lot of words you


[FILE:132:distinfo]
c8e1716e83cc398ae16824e5572ae04e0d9fc2c6b985fb0f900f5f0c96ecba1a        93002 python-src/snowballstemmer-2.2.0-py2.py3-none-any.whl

