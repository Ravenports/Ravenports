# Buildsheet autogenerated by ravenadm tool -- Do not edit.

NAMEBASE=		python-rq
VERSION=		2.1.0
KEYWORDS=		python
VARIANTS=		v12 v13
SDESC[v12]=		Library for procesing background jobs (3.12)
SDESC[v13]=		Library for procesing background jobs (3.13)
HOMEPAGE=		https://python-rq.org/
CONTACT=		Python_Automaton[python@ironwolf.systems]

DOWNLOAD_GROUPS=	main
SITES[main]=		PYPIWHL/3f/b3/e691454a551366c71248197f9050e4564f85d15c5d8a5c167ecac4411c40
DISTFILE[1]=		rq-2.1.0-py3-none-any.whl:main
DIST_SUBDIR=		python-src
DF_INDEX=		1
SPKGS[v12]=		single
SPKGS[v13]=		single

OPTIONS_AVAILABLE=	PY312 PY313
OPTIONS_STANDARD=	none
VOPTS[v12]=		PY312=ON PY313=OFF
VOPTS[v13]=		PY312=OFF PY313=ON

DISTNAME=		rq-2.1.0.dist-info

GENERATED=		yes

[PY312].RUN_DEPENDS_ON=			python-click:single:v12
					python-redis:single:v12
[PY312].USES_ON=			python:v12,wheel

[PY313].RUN_DEPENDS_ON=			python-click:single:v13
					python-redis:single:v13
[PY313].USES_ON=			python:v13,wheel

[FILE:2167:descriptions/desc.single]
RQ (_Redis Queue_) is a simple Python library for queueing jobs and
processing
them in the background with workers.  It is backed by Redis and it is
designed
to have a low barrier to entry.  It should be integrated in your web stack
easily.

RQ requires Redis >= 3.0.0.

[Build status]
[PyPI]
[Coverage]
[![Code style: Ruff]](https://github.com/astral-sh/ruff)

Full documentation can be found [here][d].

## Support RQ

If you find RQ useful, please consider supporting this project via
[Tidelift].

## Getting started

First, run a Redis server, of course:

```console
$ redis-server
```

To put jobs on queues, you don't have to do anything special, just define
your typically lengthy or blocking function:

```python
import requests

def count_words_at_url(url):
    """Just an example function that's called async."""
    resp = requests.get(url)
    return len(resp.text.split())
```

Then, create an RQ queue:

```python
from redis import Redis
from rq import Queue

queue = Queue(connection=Redis())
```

And enqueue the function call:

```python
from my_module import count_words_at_url
job = queue.enqueue(count_words_at_url, 'http://nvie.com')
```

Scheduling jobs are also similarly easy:

```python
# Schedule job to run at 9:15, October 10th
job = queue.enqueue_at(datetime(2019, 10, 10, 9, 15), say_hello)

# Schedule job to run in 10 seconds
job = queue.enqueue_in(timedelta(seconds=10), say_hello)
```

Retrying failed jobs is also supported:

```python
from rq import Retry

# Retry up to 3 times, failed job will be requeued immediately
queue.enqueue(say_hello, retry=Retry(max=3))

# Retry up to 3 times, with configurable intervals between retries
queue.enqueue(say_hello, retry=Retry(max=3, interval=[10, 30, 60]))
```

For a more complete example, refer to the [docs][d].  But this is the
essence.

### The worker

To start executing enqueued function calls in the background, start a
worker
from your project's directory:

```console
$ rq worker --with-scheduler
*** Listening for work on default
Got count_words_at_url('http://nvie.com') from default
Job result = 818
*** Listening for work on default
```

That's about it.

## Installation



[FILE:115:distinfo]
3c6892c6ca848e5fb47c1875399a66f13656bf0e123bf725d9aa9a12718e2fdf        96482 python-src/rq-2.1.0-py3-none-any.whl

